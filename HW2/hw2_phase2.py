# -*- coding: utf-8 -*-
"""HW2-phase2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13Jjt-JwxQyufQ0BP2OpFJTCMUstgR7hw
"""

import numpy as np
import pandas as pd
from datasets import load_dataset
from argparse import ArgumentParser, Namespace
from pathlib import Path

def main(args):
  df_context = pd.read_json(args.context_file, orient='values')
  df_test = pd.read_json(args.test_file)
  test_labels = pd.read_csv("context_predict.json")

  contexts = df_context[0]

  relevant = []
  for p, a in zip(df_test.paragraphs, test_labels.pred):
    relevant.append(p[a])
  df_test["relevant"] = relevant

  df_test["answer"] = [{"text":"hi", "start":0} for i in range(len(df_test))]
  df_test.to_json("test_qa.json", "records")
  data_files = {"squad_test": "test_qa.json"}
  datasets = load_dataset("json", data_files=data_files, field=slice(None))

  def encoder(examples):
    num_samples = len(examples["id"])
    return {
        "id": examples["id"],
        "title" :examples["id"],
        "context": [contexts[r] for r in examples["relevant"]],
        "question": examples["question"],
        "answers": [{"text":d["text"], "answer_start": [d["start"]]} for d in examples["answer"]]
    }
  # only test(one loop runs)
  for target in data_files.keys():
      dataset = datasets[target]
      dataset = dataset.map(encoder, batched=True, batch_size=512, remove_columns=dataset.column_names)
      dataset.to_json(f"{target}.json")


#parse
def parse_args() -> Namespace:
    parser = ArgumentParser()
    parser.add_argument(
        "--context_file",
        type=Path, 
        help="Path to the context file.",
        required=True
    )
    parser.add_argument(
        "--test_file",
        type=Path,
        help="Path to the test file.",
        required=True
    )

    args = parser.parse_args()
    return args

# main 
if __name__ == "__main__":
    args = parse_args()
    main(args)